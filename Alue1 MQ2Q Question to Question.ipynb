{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1ae0334-5eeb-4062-b380-a42acd260608",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install shiba shiba-model evaluate datasets wandb arabert  accelerate -U nltk torchmetrics==0.3.2 transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e78bcf5d-aded-4be5-b93a-ed7580614867",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torchmetrics\n",
    "import torch\n",
    "import transformers\n",
    "from datasets import load_dataset, Dataset\n",
    "from transformers import HfArgumentParser, Trainer, EvalPrediction\n",
    "\n",
    "from shiba import ShibaForClassification, CodepointTokenizer\n",
    "from training.helpers import DataArguments, get_base_shiba_state_dict,get_model_hyperparams, ShibaClassificationArgs, \\\n",
    "    ClassificationDataCollator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98999aa3-2e36-49cc-b380-3a2cd7c5687b",
   "metadata": {},
   "source": [
    "<h1> Choose the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37f7f657-65f9-4d7a-b3af-54c8ecf28d7b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_path = '../checkpoint-611960.pt'\n",
    "seg_enable = True\n",
    "bert_model_name = \"aubmindlab/bert-base-arabertv02\"\n",
    "apply_farasa=False\n",
    "file_save = 'Submit_64_05'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49dcc4b9-1cc7-4e3a-88d6-9a7c9928103d",
   "metadata": {},
   "source": [
    "<h1> Read the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8e52536-f22f-448e-860a-4f6b208fd366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "categories :  {0: 0, 1: 1}\n",
      "id_by_category :  {0: 0, 1: 1}\n"
     ]
    }
   ],
   "source": [
    "transformers.logging.set_verbosity_info()\n",
    "device = \"cuda\"\n",
    "parser = HfArgumentParser((ShibaClassificationArgs, DataArguments))\n",
    "\n",
    "prediction_label = 'label'\n",
    "\n",
    "df_train = pd.read_csv(\"data/q2q_similarity_workshop_v2.1.tsv\", sep=\"\\t\")\n",
    "df_testOrignal = pd.read_csv(\"data/q2q_no_labels_v1.0.tsv\", sep=\"\\t\")\n",
    "\n",
    "categories = {idx: cat_name for idx, cat_name in enumerate(set(df_train[prediction_label]))}\n",
    "id_by_category = {val: key for key, val in categories.items()}\n",
    "\n",
    "print(\"categories : \", categories)\n",
    "print(\"id_by_category : \", id_by_category)\n",
    "df_train = Dataset.from_pandas(df_train)\n",
    "df_test = Dataset.from_pandas(df_testOrignal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52384ca3-eb8b-47e1-aa1c-0ee9c62111d2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>QuestionPairID</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>كم عدد حروف الفاتحة؟</td>\n",
       "      <td>كيف تكون فقيهاً؟</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>هل حلال أكل الضبع؟</td>\n",
       "      <td>هل أكل الضبع حلال أم حرام؟</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>كم عدد الركعات في كل صلاة؟</td>\n",
       "      <td>كم عدد ركعات الصلوات المفروضة؟</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>كيف أؤمن بالله؟</td>\n",
       "      <td>كيف أكون مؤمناً؟</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>لماذا سميت حواء بهذا الاسم؟</td>\n",
       "      <td>كيف عذب الله قوم ثمود؟</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3995</th>\n",
       "      <td>3996</td>\n",
       "      <td>كيف تحصل على الرزق؟</td>\n",
       "      <td>لماذا خلق الله الإنسان؟</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3996</th>\n",
       "      <td>3997</td>\n",
       "      <td>كيف يكون الجهاد باللسان؟</td>\n",
       "      <td>أين غرق فرعون؟</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3997</th>\n",
       "      <td>3998</td>\n",
       "      <td>كيف تتعلم قراءة القرآن بطريقة صحيحة؟</td>\n",
       "      <td>كيف أتعلم تلاوة القرآن الكريم؟</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3998</th>\n",
       "      <td>3999</td>\n",
       "      <td>كيف ازيد كثافة شعري؟</td>\n",
       "      <td>كيف تجعل شعرك كثيف؟</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999</th>\n",
       "      <td>4000</td>\n",
       "      <td>كيف اكون هادئة الاعصاب؟</td>\n",
       "      <td>كيف أنام نوم عميق وهادئ؟</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      QuestionPairID                             question1  \\\n",
       "0                  1                  كم عدد حروف الفاتحة؟   \n",
       "1                  2                    هل حلال أكل الضبع؟   \n",
       "2                  3            كم عدد الركعات في كل صلاة؟   \n",
       "3                  4                       كيف أؤمن بالله؟   \n",
       "4                  5           لماذا سميت حواء بهذا الاسم؟   \n",
       "...              ...                                   ...   \n",
       "3995            3996                   كيف تحصل على الرزق؟   \n",
       "3996            3997              كيف يكون الجهاد باللسان؟   \n",
       "3997            3998  كيف تتعلم قراءة القرآن بطريقة صحيحة؟   \n",
       "3998            3999                  كيف ازيد كثافة شعري؟   \n",
       "3999            4000               كيف اكون هادئة الاعصاب؟   \n",
       "\n",
       "                           question2  \n",
       "0                   كيف تكون فقيهاً؟  \n",
       "1         هل أكل الضبع حلال أم حرام؟  \n",
       "2     كم عدد ركعات الصلوات المفروضة؟  \n",
       "3                   كيف أكون مؤمناً؟  \n",
       "4             كيف عذب الله قوم ثمود؟  \n",
       "...                              ...  \n",
       "3995         لماذا خلق الله الإنسان؟  \n",
       "3996                  أين غرق فرعون؟  \n",
       "3997  كيف أتعلم تلاوة القرآن الكريم؟  \n",
       "3998             كيف تجعل شعرك كثيف؟  \n",
       "3999        كيف أنام نوم عميق وهادئ؟  \n",
       "\n",
       "[4000 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_testOrignal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c902096b-032e-48a7-9585-eeea46b81f30",
   "metadata": {},
   "source": [
    "<h1> Check files count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "512821a6-c6ab-42f2-a81b-6f71b05324a1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11997, 4000)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_train), len(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76bb825e-7b3a-4151-9baf-4cc4ce72cef1",
   "metadata": {},
   "source": [
    "# Pre-Process data ( if needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc8f49ea-6392-4df5-8a66-83072e919fb1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "if seg_enable:\n",
    "    from arabert.preprocess import ArabertPreprocessor\n",
    "\n",
    "    arabert_prep = ArabertPreprocessor(model_name=bert_model_name, apply_farasa_segmentation=apply_farasa)\n",
    "    # arabert_prep.preprocess()\n",
    "    df_train = pd.DataFrame(df_train)\n",
    "    df_test =  pd.DataFrame(df_test)\n",
    "\n",
    "    df_train['question1'] =  df_train['question1'].apply(arabert_prep.preprocess)\n",
    "    df_train['question2'] =  df_train['question2'].apply(arabert_prep.preprocess)\n",
    "    df_test['question1'] =  df_test['question1'].apply(arabert_prep.preprocess)\n",
    "    df_test['question2'] =  df_test['question2'].apply(arabert_prep.preprocess)\n",
    "    df_train = Dataset.from_pandas(df_train)\n",
    "    df_test = Dataset.from_pandas(df_test)\n",
    "    print(\"done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7041c25-d061-4a2e-9044-f0a8108d0d1b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>QuestionPairID</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>كم عدد حروف الفاتحة ؟</td>\n",
       "      <td>كيف تكون فقيها ؟</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>هل حلال أكل الضبع ؟</td>\n",
       "      <td>هل أكل الضبع حلال أم حرام ؟</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>كم عدد الركعات في كل صلاة ؟</td>\n",
       "      <td>كم عدد ركعات الصلوات المفروضة ؟</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>كيف أؤمن بالله ؟</td>\n",
       "      <td>كيف أكون مؤمنا ؟</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>لماذا سميت حواء بهذا الاسم ؟</td>\n",
       "      <td>كيف عذب الله قوم ثمود ؟</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3995</th>\n",
       "      <td>3996</td>\n",
       "      <td>كيف تحصل على الرزق ؟</td>\n",
       "      <td>لماذا خلق الله الإنسان ؟</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3996</th>\n",
       "      <td>3997</td>\n",
       "      <td>كيف يكون الجهاد باللسان ؟</td>\n",
       "      <td>أين غرق فرعون ؟</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3997</th>\n",
       "      <td>3998</td>\n",
       "      <td>كيف تتعلم قراءة القرآن بطريقة صحيحة ؟</td>\n",
       "      <td>كيف أتعلم تلاوة القرآن الكريم ؟</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3998</th>\n",
       "      <td>3999</td>\n",
       "      <td>كيف ازيد كثافة شعري ؟</td>\n",
       "      <td>كيف تجعل شعرك كثيف ؟</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999</th>\n",
       "      <td>4000</td>\n",
       "      <td>كيف اكون هادئة الاعصاب ؟</td>\n",
       "      <td>كيف أنام نوم عميق وهادئ ؟</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      QuestionPairID                              question1  \\\n",
       "0                  1                  كم عدد حروف الفاتحة ؟   \n",
       "1                  2                    هل حلال أكل الضبع ؟   \n",
       "2                  3            كم عدد الركعات في كل صلاة ؟   \n",
       "3                  4                       كيف أؤمن بالله ؟   \n",
       "4                  5           لماذا سميت حواء بهذا الاسم ؟   \n",
       "...              ...                                    ...   \n",
       "3995            3996                   كيف تحصل على الرزق ؟   \n",
       "3996            3997              كيف يكون الجهاد باللسان ؟   \n",
       "3997            3998  كيف تتعلم قراءة القرآن بطريقة صحيحة ؟   \n",
       "3998            3999                  كيف ازيد كثافة شعري ؟   \n",
       "3999            4000               كيف اكون هادئة الاعصاب ؟   \n",
       "\n",
       "                            question2  \n",
       "0                    كيف تكون فقيها ؟  \n",
       "1         هل أكل الضبع حلال أم حرام ؟  \n",
       "2     كم عدد ركعات الصلوات المفروضة ؟  \n",
       "3                    كيف أكون مؤمنا ؟  \n",
       "4             كيف عذب الله قوم ثمود ؟  \n",
       "...                               ...  \n",
       "3995         لماذا خلق الله الإنسان ؟  \n",
       "3996                  أين غرق فرعون ؟  \n",
       "3997  كيف أتعلم تلاوة القرآن الكريم ؟  \n",
       "3998             كيف تجعل شعرك كثيف ؟  \n",
       "3999        كيف أنام نوم عميق وهادئ ؟  \n",
       "\n",
       "[4000 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb7c1538-8fe9-4290-a163-ad203d6f3960",
   "metadata": {},
   "source": [
    "<h1> Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96084fc7-90db-4c9e-8ca3-bda9727a8f75",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dropout': 0.1, 'deep_transformer_stack_layers': 12, 'local_attention_window': 128}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and using base shiba states from ../checkpoint-611960.pt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = CodepointTokenizer()\n",
    "model_hyperparams = {'dropout': 0.1, 'deep_transformer_stack_layers': 12, 'local_attention_window': 128}\n",
    "print(model_hyperparams)\n",
    "model = ShibaForClassification(vocab_size=len(categories), **model_hyperparams)\n",
    "data_collator = ClassificationDataCollator()\n",
    "print('Loading and using base shiba states from', model_path)\n",
    "checkpoint_state_dict = torch.load(model_path)\n",
    "model.shiba_model.load_state_dict(get_base_shiba_state_dict(checkpoint_state_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120f545d-1e7d-42b9-afbc-b58afc95d016",
   "metadata": {},
   "source": [
    "<h1>Input IDs Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "04750222-c969-4863-8139-843b163be456",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_example(example: Dict) -> Dict:\n",
    "    return {\n",
    "        'input_ids': tokenizer.encode([example['question1'], example['question2']])['input_ids'][:model.config.max_length],\n",
    "        'labels': id_by_category[example[prediction_label]]\n",
    "    }\n",
    "def process_exampleTemp(example: Dict) -> Dict:\n",
    "    return {\n",
    "        'input_ids': tokenizer.encode([example['question1'], example['question2']])['input_ids'][:model.config.max_length],\n",
    "        'labels': 0\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e952ccbe-9bfa-43d2-8036-dd3d64f280e3",
   "metadata": {},
   "source": [
    "<h1> Compute Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "997544c5-69cb-402b-a67f-3aeb2844e736",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred: EvalPrediction) -> Dict:\n",
    "    try:\n",
    "        # Convert predictions and labels to PyTorch tensors\n",
    "        # label_probs = torch.tensor(pred.predictions)\n",
    "        label_probs, embeddings = pred.predictions\n",
    "        labels = torch.tensor(pred.label_ids)\n",
    "        label_probs = torch.exp(torch.tensor(label_probs))  # undo the log in log softmax, get indices\n",
    "        # # Compute accuracy\n",
    "        # accuracy = torchmetrics.functional.accuracy(label_probs, labels, num_classes=len(categories))\n",
    "\n",
    "        # Compute F1 score\n",
    "        f1_score = torchmetrics.functional.f1(label_probs, labels, average='macro', num_classes=len(categories))\n",
    "\n",
    "        # Compute recall\n",
    "        recall = torchmetrics.functional.recall(label_probs, labels, average='macro', num_classes=len(categories))\n",
    "\n",
    "        # Compute precision\n",
    "        precision = torchmetrics.functional.precision(label_probs, labels, average='macro', num_classes=len(categories))\n",
    "\n",
    "        # print(\"label_probs : \", label_probs, \" labels : \", labels)\n",
    "\n",
    "        metrics = {\n",
    "            # 'accuracy': accuracy.item(),\n",
    "            'f1_score': f1_score.item(),\n",
    "            'recall': recall.item(),\n",
    "            'precision': precision.item()\n",
    "        }\n",
    "\n",
    "        # print(\"metrics : \", metrics)\n",
    "        # raise NotImplementedError\n",
    "\n",
    "        return metrics\n",
    "    except:\n",
    "        print(\"pred : \", pred)\n",
    "        print(\"pred.predictions : \", pred.predictions)\n",
    "        print(\"label_probs : \", label_probs)\n",
    "        print(\"label_probs.size : \", label_probs.size())\n",
    "        print(\"labels : \", labels)\n",
    "        print(\"labels.size() : \", labels.size())\n",
    "\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc9d59d-5bcd-4308-89a7-54a37e87c062",
   "metadata": {},
   "source": [
    "<h1> Fine-tune args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ec5c238-c697-4d4b-95c3-966cac0831e0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n"
     ]
    }
   ],
   "source": [
    "training_args = ShibaClassificationArgs(\n",
    "    per_device_eval_batch_size=64,\n",
    "    per_device_train_batch_size=64,\n",
    "    data_seed=42,\n",
    "    seed=42,\n",
    "    do_eval=True,\n",
    "    do_predict=True,\n",
    "    do_train=True,\n",
    "    dropout=0.5,\n",
    "    eval_accumulation_steps=None,\n",
    "    eval_delay=0,\n",
    "    eval_steps=100,\n",
    "    evaluation_strategy='steps',\n",
    "    gradient_accumulation_steps=1,\n",
    "    num_train_epochs=10,\n",
    "    output_dir=\"fine_result\",\n",
    "    prediction_loss_only=False,\n",
    "    report_to=[],\n",
    "    run_name=\"fine_result\",\n",
    "    save_strategy='no',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36c11aa-5324-46e6-95c7-2873f311f6d4",
   "metadata": {},
   "source": [
    "<h1> Setup the trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c9e1b475-99a5-454b-bea6-1d28ad0f9e6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c85235ecc2e24f75b4d35c67d233af3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/11997 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdca02ae272e478fad1f2d2bdc297a9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/11997 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using auto half precision backend\n"
     ]
    }
   ],
   "source": [
    "# print(all_data)\n",
    "trainer = Trainer(model=model,\n",
    "                args=training_args,\n",
    "                data_collator=data_collator,\n",
    "                train_dataset=df_train.map(process_example, remove_columns=list(df_train[0].keys())),\n",
    "                eval_dataset=df_train.map(process_example, remove_columns=list(df_train[0].keys())),\n",
    "                compute_metrics=compute_metrics,\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20add24d-64a0-4ff8-83f4-6bd7bf005fc1",
   "metadata": {},
   "source": [
    "<h1> Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eca7ad8d-8080-43e8-996f-83d4444e5d2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 11,997\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 64\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1,880\n",
      "  Number of trainable parameters = 120,767,234\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1880' max='1880' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1880/1880 10:53, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.691700</td>\n",
       "      <td>0.684693</td>\n",
       "      <td>0.526315</td>\n",
       "      <td>0.546226</td>\n",
       "      <td>0.562680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.671700</td>\n",
       "      <td>0.707321</td>\n",
       "      <td>0.571254</td>\n",
       "      <td>0.596370</td>\n",
       "      <td>0.608647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.638600</td>\n",
       "      <td>0.606477</td>\n",
       "      <td>0.670567</td>\n",
       "      <td>0.674761</td>\n",
       "      <td>0.673328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.596000</td>\n",
       "      <td>0.512078</td>\n",
       "      <td>0.734081</td>\n",
       "      <td>0.732660</td>\n",
       "      <td>0.737752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.517000</td>\n",
       "      <td>0.437938</td>\n",
       "      <td>0.790860</td>\n",
       "      <td>0.792494</td>\n",
       "      <td>0.790262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.426700</td>\n",
       "      <td>0.303548</td>\n",
       "      <td>0.865009</td>\n",
       "      <td>0.865195</td>\n",
       "      <td>0.864835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.381800</td>\n",
       "      <td>0.271692</td>\n",
       "      <td>0.885414</td>\n",
       "      <td>0.890150</td>\n",
       "      <td>0.886281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.319700</td>\n",
       "      <td>0.178582</td>\n",
       "      <td>0.927680</td>\n",
       "      <td>0.925560</td>\n",
       "      <td>0.931016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.246000</td>\n",
       "      <td>0.130004</td>\n",
       "      <td>0.950580</td>\n",
       "      <td>0.949898</td>\n",
       "      <td>0.951373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.198800</td>\n",
       "      <td>0.103894</td>\n",
       "      <td>0.961594</td>\n",
       "      <td>0.962525</td>\n",
       "      <td>0.960856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.190700</td>\n",
       "      <td>0.093902</td>\n",
       "      <td>0.965054</td>\n",
       "      <td>0.966222</td>\n",
       "      <td>0.964187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.161800</td>\n",
       "      <td>0.065265</td>\n",
       "      <td>0.977023</td>\n",
       "      <td>0.977224</td>\n",
       "      <td>0.976830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.145800</td>\n",
       "      <td>0.053698</td>\n",
       "      <td>0.981119</td>\n",
       "      <td>0.980616</td>\n",
       "      <td>0.981676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.118100</td>\n",
       "      <td>0.043424</td>\n",
       "      <td>0.984021</td>\n",
       "      <td>0.984627</td>\n",
       "      <td>0.983493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.116100</td>\n",
       "      <td>0.036112</td>\n",
       "      <td>0.988027</td>\n",
       "      <td>0.987368</td>\n",
       "      <td>0.988776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.091200</td>\n",
       "      <td>0.031158</td>\n",
       "      <td>0.989037</td>\n",
       "      <td>0.988328</td>\n",
       "      <td>0.989852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.076700</td>\n",
       "      <td>0.026581</td>\n",
       "      <td>0.990472</td>\n",
       "      <td>0.989818</td>\n",
       "      <td>0.991215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.071000</td>\n",
       "      <td>0.019325</td>\n",
       "      <td>0.993599</td>\n",
       "      <td>0.993466</td>\n",
       "      <td>0.993736</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 11997\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 11997\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 11997\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 11997\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 11997\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 11997\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 11997\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 11997\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 11997\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 11997\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 11997\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 11997\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 11997\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 11997\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 11997\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 11997\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 11997\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 11997\n",
      "  Batch size = 64\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training = trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ad8bc7-519b-44d1-b6bb-98b3ab95c38d",
   "metadata": {},
   "source": [
    "<h1> Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d9f2e88a-9647-4c44-a090-693b15b124df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'function'=<function process_exampleTemp at 0x7f4d115341f0> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08c37013484b4a40b9b17431541ec605",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 4000\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred = trainer.predict(df_test.map(process_exampleTemp, remove_columns=list(df_test[0].keys())))\n",
    "df_testOrignal['prediction'] = [categories[x] for x in np.argmax(pred.predictions[0], axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42bcb15f-9212-4e82-b73e-553b9c628b7e",
   "metadata": {},
   "source": [
    "<h1> Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "17e1cbaf-6edb-42f9-b9a0-d59c0ca616db",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>QuestionPairID</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   QuestionPairID  prediction\n",
       "0               1           0\n",
       "1               2           1\n",
       "2               3           1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_testOrignal[['QuestionPairID', 'prediction']].to_csv(file_save+'/q2q.tsv', index=False, sep=\"\\t\")\n",
    "pd.read_csv(file_save+\"/q2q.tsv\", sep=\"\\t\").head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bf2b710f-ef02-4917-9c06-adf6a12ddf5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2380f24-2f6d-46be-a195-4d806d854489",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
